% !TeX spellcheck = en_US
\chapter{Research Proposal}

\section{Introduction and Background of Interest}

\todo{ignore for now}

Robots are complex machines designed to support our lives.

Since mid 19th century, its emergence has received research attention in both the academic and industry. The first major application was in the automotive industry. Its presence is entering our lives in different fields is spreading even more and more. \todo{move to unstructured environments and challenges}

\section{Literature Review}

To my best current knowledge, robot arms have made significant improvement, but are still far from delivering general-purpose tasks. Initially, robot arms are programmed explicitly and only capable of working in the known and constrained environment of factories. Progress in different fields of technology has provided the robots more inputs (\eg, vision, audio, haptic) to operate in dynamic and unstructured environments. State-of-the-art robot manipulators can deliver complex tasks, \eg, cooking \cite{moley}, making coffee \cite{coffeemaster}, and cleaning around the house \cite{bothandy}. However, the behaviors of these models are still awkwardly disruptive and far from the mastery level of the human hand's dexterity. In addition, instead of having the adaptability for a wide range of conditions, most models still operate in designed environments with known tools and settings.

\subsection{Robotic Grasping}

Grasping is one of the critical and unavoidable problems for robot manipulators, especially for logistic and service robots. Overall, most successful grasping approaches are empirical, using deep learning on a large dataset to find the best grasping candidates. Majority of models are supervised learning using single-modal input, \ie RGB images. A few have considered multi-modal inputs: RGB with depth images or tactile input. Approaches, which take tactile data, use it as the sole input to improve grasp stability, adaptability to object's weight \cite{bekiroglu2011assessing, li2014learning}, a few combine with other modality for improvement \cite{calandra2017feeling}. \cite{bohg2013data, caldera2018review, li2019review, kleeberger2020survey}

\subsection{Reinforcement Learning}
\ac{RL} is a branch of \ac{ML} approaches for learning decision making from experiences. Given a sufficient amount of input data, it can potentially surpass human's ability for reasoning, \eg, playing games like Go, chess, Atari. Most works on robot manipulators are currently directed to object picking and hand-over tasks. To meet the need for data, sim-to-real transfer techniques \cite{kleeberger2020survey} and collective learning are being studied \cite{yahya2017collective}. Unlike in other domains of \ac{ML}, it's difficult to implement transfer learning with \ac{RL}, given different robot arms, gripper and sensor types. Various directions are being researched to tackle this issue, \ie offline \ac{RL}, novel exploration strategies, multi-task learning, meta-learning. \cite{kober2013reinforcement, li2017deep, arulkumaran2017deep, singh2021reinforcement}

\section{Approaches and Choice of Methods}
\subsection{Key Points for Improvement}
Prior works on robotic manipulators were limited on their utilization of tactile sensors. Because complex hand and arm behaviors need force and pressure feedback, leveraging the manipulators to the dexterity level of human's arms requires these sensors. However, tactile sensors are currently been used mostly for the development of soft robotics \cite{haddadin2018tactile}. For grasping tasks, despite certain successes from using visual and tactile input separately, there hasn't being a multi-modal approach capable of combining the strengths of both sides, \ie, accurate localization, adaptability to object properties. A model, which has knowledge from both visual and tactile sources, promises to deliver complex manipulation tasks with diverse objects.

It's still challenging to generalize and apply \ac{RL} to different robotic manipulator's tasks. In general, \ac{RL} did make a convincing case about its potential to surpass human's ability in some specific applications, \eg, playing Go, chess. However, in other fields, practical applications are yet scattered and limited. For robotic manipulators, current focuses are still around object picking and handling tasks \cite{singh2021reinforcement}. One of the major causes for this situation is the current gap in generalization and transfer learning. Directions for improvements are meta-learning, multi-task learning, \etc \cite{kober2013reinforcement}.

\subsection{Approaches and Research Contributions}
The progress I wish to work towards concerns robotic collective learning for collaborative tasks. For example, a system of multiple robot arms learning to play 2v2 table tennis, pack an item or cook. Building up towards this progress, I intend to work and gain more experiences on the following problems:

\begin{enumerate}
	\item A multi-modal approach for robotic picking task: combines visual and tactile input into a \ac{DL} model. Prior works on tactile sensors have proven their potentials in inference of object properties \cite{luo2017robotic} and improving robotic grasping \cite{yamaguchi2019recent}. I want to further extend recent advances in tactile sensors to a multi-modal approach.
	\item Visual imitation learning: copies behaviors from visual demonstrations (videos). Prior works are still restricted with certain types of input data, tasks \cite{finn2017one, sharma2019third}. 	Based on previous progress on teleoperation \cite{handa2020dexpilot}, I want to extend further to learn in different problem settings, with generalized tasks, and also apply offline \ac{RL}.
	\item A data collection pipeline for robot manipulators: preferably from using the above visual imitation learning, to map human’s arm movements to manipulator's. The data would contain both visual and tactile information. It would then be used for the learning of other robotic tasks or in other settings (different types of arm, gripper, \etc).
	\item Meta-learning with different manipulation tasks.
\end{enumerate}

Moreover, I'm also interested in exploring the usage of certain \ac{DL} models, techniques:
\begin{itemize}
	\item Generative model: Generating expert-like samples.
	\item Score matching
	\item Exploration for imitation learning
\end{itemize}

\section{Proposed Research Plan}

\todo{}

\todo{How the lab is related to this research plan?}
\begin{itemize}
	\item There is alignment in our directions
	\item Fit the position
\end{itemize}

\todo{Give compliments to their works!}
\begin{itemize}
	\item mention more explicitly regarding the topics, what research they have done
	\item I read your papers about … let alone the works on …
\end{itemize}
