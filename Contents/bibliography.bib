% Encoding: UTF-8
@STRING{ai		= {Artificial Intelligence} }
@STRING{amai	= {Annals of Mathematics and Artificial Intelligence} }
@STRING{ar      = {Autonomous Robots} }
@STRING{ifac    = {IFAC Proceedings Volumes} }
@STRING{fsr		= {Field and Service Robotics} }

@STRING{arso	= {Proc.~of the IEEE Workshop on Advanced Robotics and its Social Impacts (ARSO)} }
@STRING{cvpr    = {Proc.~of the IEEE/CVF Int.~Conf.~on Computer Vision and Pattern Recognition (CVPR)} }
@STRING{flairs	 = {Proc.~of the Int.~Conf.~of Florida Artificial Intelligence Research Society (FLAIRS)} }
@STRING{icml	= {Proc.~of the Int.~Conf.~on Machine Learning (ICML} }
@STRING{icar    = {Proc.~of the Int.~Conf.~on Advanced Robotics (ICAR)} }
@STRING{icra    = {Proc.~of the IEEE Intl.~Conf.~on Robotics \& Automation (ICRA)} }
@STRING{iecon   = {Proc.~of the IEEE Anl.~Conf.~on Industrial Electronics Society (IECON)} }
@STRING{iros    = {Proc.~of the IEEE/RSJ Int.~Conf.~on Intelligent Robots and Systems (IROS)} }
@STRING{wcica	= {Proc.~of the World Congress on Intelligent Control and Automation (WCICA)} }
@STRING{NeurIPS	= {Proc.~of the Conf.~on Neural Information Processing Systems (NeurIPS)} }

@STRING{ijars   = {Int.~Journal of Advanced Robotic Systems (IJARS} }
@STRING{ijnc	= {Int.~Journal of Natural Computing} }
@STRING{ras		= {Journal on Robotics and Autonomous Systems (RAS)} }
@STRING{jcos    = {Journal of Computers \& Operations Research} }
@STRING{jd		= {Journal of Drones} }
@STRING{je		= {Journal of Energies} }
@STRING{jfr     = {Journal of Field Robotics (JFR)} }
@STRING{jirs    = {Journal of Intelligent and Robotic Systems (JIRS)} }
@STRING{jis		= {Journal of Information Sciences} }
@STRING{jise    = {Journal of Information Science \& Engineering} }
@STRING{jrs		= {Journal of Robotic Systems} }
@STRING{js		= {Journal of Sensors} }
@STRING{jml		= {Journal of Machine Learning} }
@STRING{jmlr	= {Journal of Machine Learning Research} }

@STRING{mdpi	= {Multidisciplinary Digital Publishing Institute} }
@STRING{or		= {Operations Research} }
@STRING{orl		= {Operations Research Letters} }
@STRING{tsmc	= {IEEE Trans. on Systems, Man, and Cybernetics} }

@book{goodfellow2016deep,
	title={Deep learning},
	author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year={2016},
	publisher={MIT press}
}
@book{vu2018mlcb,
	title={Deep learning},
	author={Vu, Huu~Tiep},
	year={2018},
}
@article{tjaden2018,
	author = {Tjaden, Henning and Schwanecke, Ulrich and Schömer, Elmar and Cremers, Daniel},
	year = {2018},
	month = {07},
	title = {A Gauss-Newton Approach to Real-Time Monocular Multiple Object Tracking}
}
@book{frisiusradio,
	title={De radio astronomico et geometrico liber},
	year = {1545},
	author={Frisius, Rainer Gemma},
	publisher={Ap. Gul Cavellat}
}
@book{thrun2006probalistic,
	title={Probalistic robotics},
	author={Thrun, Sebastian and Burgard, Wolfram and Fox, Dieter},
	year={2006},
	publisher={Emerald Group Publishing Limited}
}
@inproceedings{ross2011ais,
	title={A reduction of imitation learning and structured prediction to no-regret online learning},
	author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
	booktitle={Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
	pages={627--635},
	year={2011},
	organization={ Workshop and Conference Proceedings}
}
@article{williams1992jml,
	title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
	author={Williams, Ronald J},
	journal=jml,
	volume={8},
	number={3},
	pages={229--256},
	year={1992},
	publisher={Springer}
}
@article{peters2008nn,
	title={Reinforcement learning of motor skills with policy gradients},
	author={Peters, Jan and Schaal, Stefan},
	journal={Neural Networks},
	volume={21},
	number={4},
	pages={682--697},
	year={2008},
	publisher={Elsevier}
}
@inproceedings{schulman2015icml,
	title={Trust region policy optimization},
	author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
	booktitle=icml,
	pages={1889--1897},
	year={2015},
	organization={PMLR}
}
@inproceedings{levine2013icml,
	title={Guided policy search},
	author={Levine, Sergey and Koltun, Vladlen},
	booktitle=icml,
	pages={1--9},
	year={2013},
	organization={PMLR}
}
@article{schulman2017proximal,
	title={Proximal policy optimization algorithms},
	author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	journal={arXiv preprint arXiv:1707.06347},
	year={2017}
}
@inproceedings{thomas2014icml,
	title={Bias in natural actor-critic algorithms},
	author={Thomas, Philip},
	booktitle=icml,
	pages={441--448},
	year={2014},
	organization={PMLR}
}
@article{gu2016q,
	title={Q-prop: Sample-efficient policy gradient with an off-policy critic},
	author={Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
	journal={arXiv preprint arXiv:1611.02247},
	year={2016}
}
@article{sutton1999policy,
	title={Policy gradient methods for reinforcement learning with function approximation},
	author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
	journal=NeurIPS,
	volume={12},
	year={1999}
}
@inproceedings{mnih2016icml,
	title={Asynchronous methods for deep reinforcement learning},
	author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
	booktitle=icml,
	pages={1928--1937},
	year={2016},
	organization={PMLR}
}
@article{schulman2015high,
	title={High-dimensional continuous control using generalized advantage estimation},
	author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
	journal={arXiv preprint arXiv:1506.02438},
	year={2015}
}
@article{munos2016safe,
	title={Safe and efficient off-policy reinforcement learning},
	author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
	journal=NeurIPS,
	volume={29},
	year={2016}
}
@article{browne2012survey,
	title={A survey of monte carlo tree search methods},
	author={Browne, Cameron B and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M and Cowling, Peter I and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
	journal={IEEE Transactions on Computational Intelligence and AI in games},
	volume={4},
	number={1},
	pages={1--43},
	year={2012},
	publisher={IEEE}
}
@inproceedings{tassa2012iros,
	title={Synthesis and stabilization of complex behaviors through online trajectory optimization},
	author={Tassa, Yuval and Erez, Tom and Todorov, Emanuel},
	booktitle=iros,
	pages={4906--4913},
	year={2012},
	organization={IEEE}
}
@book{jacobson1970differential,
	title={Differential dynamic programming},
	author={Jacobson, David H and Mayne, David Q},
	number={24},
	year={1970},
	publisher={Elsevier Publishing Company}
}
@article{levine2014learning,
	title={Learning neural network policies with guided policy search under unknown dynamics},
	author={Levine, Sergey and Abbeel, Pieter},
	journal=NeurIPS,
	volume={27},
	year={2014}
}
@inproceedings{blundell2015icml,
	title={Weight uncertainty in neural network},
	author={Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
	booktitle=icml,
	pages={1613--1622},
	year={2015},
	organization={PMLR}
}
@article{gal2017concrete,
	title={Concrete dropout},
	author={Gal, Yarin and Hron, Jiri and Kendall, Alex},
	journal=NeurIPS,
	volume={30},
	year={2017}
}
@article{chua2018deep,
	title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
	author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
	journal=NeurIPS,
	volume={31},
	year={2018}
}
@inproceedings{nagabandi2020deep,
	title={Deep dynamics models for learning dexterous manipulation},
	author={Nagabandi, Anusha and Konolige, Kurt and Levine, Sergey and Kumar, Vikash},
	booktitle={Conference on Robot Learning},
	pages={1101--1112},
	year={2020},
	organization={PMLR}
}
@inproceedings{deisenroth2011icml,
	title={PILCO: A model-based and data-efficient approach to policy search},
	author={Deisenroth, Marc and Rasmussen, Carl E},
	booktitle=icml,
	pages={465--472},
	year={2011},
	organization={Citeseer}
}
@inproceedings{feinberg2018icml,
	title={Model-based value expansion for efficient model-free reinforcement learning},
	author={Feinberg, Vladimir and Wan, Alvin and Stoica, Ion and Jordan, Michael I and Gonzalez, Joseph E and Levine, Sergey},
	booktitle=icml,
	year={2018}
}
@article{buckman2018sample,
	title={Sample-efficient reinforcement learning with stochastic ensemble value expansion},
	author={Buckman, Jacob and Hafner, Danijar and Tucker, George and Brevdo, Eugene and Lee, Honglak},
	journal=NeurIPS,
	volume={31},
	year={2018}
}
@inproceedings{finn2017icra,
	title={Deep visual foresight for planning robot motion},
	author={Finn, Chelsea and Levine, Sergey},
	booktitle=icra,
	pages={2786--2793},
	year={2017},
	organization={IEEE}
}
@inproceedings{ebert2017self,
	title={Self-Supervised Visual Planning with Temporal Skip Connections.},
	author={Ebert, Frederik and Finn, Chelsea and Lee, Alex X and Levine, Sergey},
	booktitle={CoRL},
	pages={344--356},
	year={2017}
}
@article{watkins1989learning,
	title={Learning from delayed rewards},
	author={Watkins, Christopher John Cornish Hellaby},
	year={1989},
	publisher={King's College, Cambridge United Kingdom}
}
@inproceedings{riedmiller2005neural,
	title={Neural fitted Q iteration--first experiences with a data efficient neural reinforcement learning method},
	author={Riedmiller, Martin},
	booktitle={European Conference on Machine Learning},
	pages={317--328},
	year={2005},
	organization={Springer}
}
@inproceedings{lange2010deep,
	title={Deep auto-encoder neural networks in reinforcement learning},
	author={Lange, Sascha and Riedmiller, Martin},
	booktitle={The 2010 International Joint Conference on Neural Networks (IJCNN)},
	pages={1--8},
	year={2010},
	organization={IEEE}
}
@article{mnih2015human,
	title={Human-level control through deep reinforcement learning},
	author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
	journal={Nature},
	volume={518},
	number={7540},
	pages={529--533},
	year={2015},
	publisher={Nature Publishing Group}
}
@inproceedings{van2016deep,
	title={Deep reinforcement learning with double q-learning},
	author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	volume={30},
	number={1},
	year={2016}
}
@inproceedings{gu2016continuous,
	title={Continuous deep q-learning with model-based acceleration},
	author={Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},
	booktitle=icml,
	pages={2829--2838},
	year={2016},
	organization={PMLR}
}
@inproceedings{wang2016dueling,
	title={Dueling network architectures for deep reinforcement learning},
	author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado and Lanctot, Marc and Freitas, Nando},
	booktitle=icml,
	pages={1995--2003},
	year={2016},
	organization={PMLR}
}
@article{lillicrap2015continuous,
	title={Continuous control with deep reinforcement learning},
	author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
	journal={arXiv preprint arXiv:1509.02971},
	year={2015}
}
@article{kalashnikov2018qt,
	title={Qt-opt: Scalable deep reinforcement learning for vision-based robotic manipulation},
	author={Kalashnikov, D and Irpan, A and Pastor, P and Ibarz, J and Herzog, A and Jang, E and Quillen, D and Holly, E and Kalakrishnan, M and Vanhoucke, V and others},
	journal={arXiv preprint arXiv:1806.10293},
	year={2018}
}
@inproceedings{parmas2018icml,
	title={PIPPS: Flexible model-based policy search robust to the curse of chaos},
	author={Parmas, Paavo and Rasmussen, Carl Edward and Peters, Jan and Doya, Kenji},
	booktitle=icml,
	pages={4065--4074},
	year={2018},
	organization={PMLR}
}
@incollection{sutton1990integrated,
	title={Integrated architectures for learning, planning, and reacting based on approximating dynamic programming},
	author={Sutton, Richard S},
	booktitle=icml,
	pages={216--224},
	year={1990},
	publisher={Elsevier}
}
@inproceedings{feinberg2018model,
	title={Model-based value expansion for efficient model-free reinforcement learning},
	author={Feinberg, Vladimir and Wan, Alvin and Stoica, Ion and Jordan, Michael I and Gonzalez, Joseph E and Levine, Sergey},
	booktitle=icml,
	year={2018}
}
@article{janner2019trust,
	title={When to trust your model: Model-based policy optimization},
	author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
	journal=NeurIPS,
	volume={32},
	year={2019}
}
@article{levine2016end,
	title={End-to-end training of deep visuomotor policies},
	author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
	journal=jmlr,
	volume={17},
	number={1},
	pages={1334--1373},
	year={2016},
	publisher={JMLR. org}
}
@article{hinton2015distilling,
	title={Distilling the knowledge in a neural network},
	author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff and others},
	journal={arXiv preprint arXiv:1503.02531},
	volume={2},
	number={7},
	year={2015}
}
@article{rusu2015policy,
	title={Policy distillation},
	author={Rusu, Andrei A and Colmenarejo, Sergio Gomez and Gulcehre, Caglar and Desjardins, Guillaume and Kirkpatrick, James and Pascanu, Razvan and Mnih, Volodymyr and Kavukcuoglu, Koray and Hadsell, Raia},
	journal={arXiv preprint arXiv:1511.06295},
	year={2015}
}
@article{parisotto2015actor,
	title={Actor-mimic: Deep multitask and transfer reinforcement learning},
	author={Parisotto, Emilio and Ba, Jimmy Lei and Salakhutdinov, Ruslan},
	journal={arXiv preprint arXiv:1511.06342},
	year={2015}
}
@article{ghosh2017divide,
	title={Divide-and-conquer reinforcement learning},
	author={Ghosh, Dibya and Singh, Avi and Rajeswaran, Aravind and Kumar, Vikash and Levine, Sergey},
	journal={arXiv preprint arXiv:1711.09874},
	year={2017}
}
@article{teh2017distral,
	title={Distral: Robust multitask reinforcement learning},
	author={Teh, Yee and Bapst, Victor and Czarnecki, Wojciech M and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
	journal=NeurIPS,
	volume={30},
	year={2017}
}
@article{chapelle2011empirical,
	title={An empirical evaluation of thompson sampling},
	author={Chapelle, Olivier and Li, Lihong},
	journal=NeurIPS,
	volume={24},
	year={2011}
}
@article{russo2014learning,
	title={Learning to optimize via information-directed sampling},
	author={Russo, Daniel and Van Roy, Benjamin},
	journal=NeurIPS,
	volume={27},
	year={2014}
}
@article{bellemare2016unifying,
	title={Unifying count-based exploration and intrinsic motivation},
	author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
	journal=NeurIPS,
	volume={29},
	year={2016}
}
@article{strehl2008analysis,
	title={An analysis of model-based interval estimation for Markov decision processes},
	author={Strehl, Alexander L and Littman, Michael L},
	journal={Journal of Computer and System Sciences},
	volume={74},
	number={8},
	pages={1309--1331},
	year={2008},
	publisher={Elsevier}
}
@inproceedings{kolter2009near,
	title={Near-Bayesian exploration in polynomial time},
	author={Kolter, J Zico and Ng, Andrew Y},
	booktitle=icml,
	pages={513--520},
	year={2009}
}
@article{tang2017exploration,
	title={\# exploration: A study of count-based exploration for deep reinforcement learning},
	author={Tang, Haoran and Houthooft, Rein and Foote, Davis and Stooke, Adam and Xi Chen, OpenAI and Duan, Yan and Schulman, John and DeTurck, Filip and Abbeel, Pieter},
	journal={Advances in neural information processing systems},
	volume={30},
	year={2017}
}
@article{burda2018exploration,
	title={Exploration by random network distillation},
	author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
	journal={arXiv preprint arXiv:1810.12894},
	year={2018}
}
@article{osband2016deep,
	title={Deep exploration via bootstrapped DQN},
	author={Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
	journal=NeurIPS,
	volume={29},
	year={2016}
}
@article{fu2017ex2,
	title={Ex2: Exploration with exemplar models for deep reinforcement learning},
	author={Fu, Justin and Co-Reyes, John and Levine, Sergey},
	journal=NeurIPS,
	volume={30},
	year={2017}
}
@article{houthooft2016vime,
	title={Vime: Variational information maximizing exploration},
	author={Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
	journal=NeurIPS,
	volume={29},
	year={2016}
}
@article{stadie2015incentivizing,
	title={Incentivizing exploration in reinforcement learning with deep predictive models},
	author={Stadie, Bradly C and Levine, Sergey and Abbeel, Pieter},
	journal={arXiv preprint arXiv:1507.00814},
	year={2015}
}
@article{schmidhuber2010formal,
	title={Formal theory of creativity, fun, and intrinsic motivation (1990--2010)},
	author={Schmidhuber, J{\"u}rgen},
	journal={IEEE transactions on autonomous mental development},
	volume={2},
	number={3},
	pages={230--247},
	year={2010},
	publisher={IEEE}
}
@inproceedings{schmidhuber1991possibility,
	title={A possibility for implementing curiosity and boredom in model-building neural controllers},
	author={Schmidhuber, J{\"u}rgen},
	booktitle={Proc. of the international conference on simulation of adaptive behavior: From animals to animats},
	pages={222--227},
	year={1991}
}
@article{nair2018visual,
	title={Visual reinforcement learning with imagined goals},
	author={Nair, Ashvin V and Pong, Vitchyr and Dalal, Murtaza and Bahl, Shikhar and Lin, Steven and Levine, Sergey},
	journal=NeurIPS,
	volume={31},
	year={2018}
}
@article{pong2019skew,
	title={Skew-fit: State-covering self-supervised reinforcement learning},
	author={Pong, Vitchyr H and Dalal, Murtaza and Lin, Steven and Nair, Ashvin and Bahl, Shikhar and Levine, Sergey},
	journal={arXiv preprint arXiv:1903.03698},
	year={2019}
}
@inproceedings{hazan2019provably,
	title={Provably efficient maximum entropy exploration},
	author={Hazan, Elad and Kakade, Sham and Singh, Karan and Van Soest, Abby},
	booktitle=icml,
	pages={2681--2691},
	year={2019},
	organization={PMLR}
}
@article{gupta2018unsupervised,
	title={Unsupervised meta-learning for reinforcement learning},
	author={Gupta, Abhishek and Eysenbach, Benjamin and Finn, Chelsea and Levine, Sergey},
	journal={arXiv preprint arXiv:1806.04640},
	year={2018}
}
@article{lee2019efficient,
	title={Efficient exploration via state marginal matching},
	author={Lee, Lisa and Eysenbach, Benjamin and Parisotto, Emilio and Xing, Eric and Levine, Sergey and Salakhutdinov, Ruslan},
	journal={arXiv preprint arXiv:1906.05274},
	year={2019}
}
@article{eysenbach2018diversity,
	title={Diversity is all you need: Learning skills without a reward function},
	author={Eysenbach, Benjamin and Gupta, Abhishek and Ibarz, Julian and Levine, Sergey},
	journal={arXiv preprint arXiv:1802.06070},
	year={2018}
}
@article{gregor2016variational,
	title={Variational intrinsic control},
	author={Gregor, Karol and Rezende, Danilo Jimenez and Wierstra, Daan},
	journal={arXiv preprint arXiv:1611.07507},
	year={2016}
}
@article{todorov2006linearly,
	title={Linearly-solvable Markov decision problems},
	author={Todorov, Emanuel},
	journal=NeurIPS,
	volume={19},
	year={2006}
}
@inproceedings{todorov2008general,
	title={General duality between optimal control and estimation},
	author={Todorov, Emanuel},
	booktitle={2008 47th IEEE Conference on Decision and Control},
	pages={4286--4292},
	year={2008},
	organization={IEEE}
}
@article{kappen2012optimal,
	title={Optimal control as a graphical model inference problem},
	author={Kappen, Hilbert J and G{\'o}mez, Vicen{\c{c}} and Opper, Manfred},
	journal=jml,
	volume={87},
	number={2},
	pages={159--182},
	year={2012},
	publisher={Springer}
}
@inproceedings{ziebart2010modeling,
	title={Modeling interaction via the principle of maximum causal entropy},
	author={Ziebart, Brian D and Bagnell, J Andrew and Dey, Anind K},
	booktitle=icml,
	year={2010}
}
@article{rawlik2012stochastic,
	title={On stochastic optimal control and reinforcement learning by approximate inference},
	author={Rawlik, Konrad and Toussaint, Marc and Vijayakumar, Sethu},
	journal={Proceedings of Robotics: Science and Systems VIII},
	year={2012}
}
@inproceedings{haarnoja2017reinforcement,
	title={Reinforcement learning with deep energy-based policies},
	author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
	booktitle=icml,
	pages={1352--1361},
	year={2017},
	organization={PMLR}
}
@article{nachum2017bridging,
	title={Bridging the gap between value and policy based reinforcement learning},
	author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
	journal=NeurIPS,
	volume={30},
	year={2017}
}
@article{schulman2017equivalence,
	title={Equivalence between policy gradients and soft q-learning},
	author={Schulman, John and Chen, Xi and Abbeel, Pieter},
	journal={arXiv preprint arXiv:1704.06440},
	year={2017}
}
@inproceedings{haarnoja2018soft,
	title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
	author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
	booktitle=icml,
	pages={1861--1870},
	year={2018},
	organization={PMLR}
}
@article{levine2018reinforcement,
	title={Reinforcement learning and control as probabilistic inference: Tutorial and review},
	author={Levine, Sergey},
	journal={arXiv preprint arXiv:1805.00909},
	year={2018}
}
@inproceedings{abbeel2004apprenticeship,
	title={Apprenticeship learning via inverse reinforcement learning},
	author={Abbeel, Pieter and Ng, Andrew Y},
	booktitle=icml,
	pages={1},
	year={2004}
}
@inproceedings{ziebart2008maximum,
	title={Maximum entropy inverse reinforcement learning.},
	author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K and others},
	booktitle={Aaai},
	volume={8},
	pages={1433--1438},
	year={2008},
	organization={Chicago, IL, USA}
}
@inproceedings{finn2016guided,
	title={Guided cost learning: Deep inverse optimal control via policy optimization},
	author={Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
	booktitle=icml,
	pages={49--58},
	year={2016},
	organization={PMLR}
}
@article{wulfmeier2015maximum,
	title={Maximum entropy deep inverse reinforcement learning},
	author={Wulfmeier, Markus and Ondruska, Peter and Posner, Ingmar},
	journal={arXiv preprint arXiv:1507.04888},
	year={2015}
}
@article{ho2016generative,
	title={Generative adversarial imitation learning},
	author={Ho, Jonathan and Ermon, Stefano},
	journal=NeurIPS,
	volume={29},
	year={2016}
}
@article{fu2017learning,
	title={Learning robust rewards with adversarial inverse reinforcement learning},
	author={Fu, Justin and Luo, Katie and Levine, Sergey},
	journal={arXiv preprint arXiv:1710.11248},
	year={2017}
}
@inproceedings{ratliff2006maximum,
	title={Maximum margin planning},
	author={Ratliff, Nathan D and Bagnell, J Andrew and Zinkevich, Martin A},
	booktitle=icml,
	pages={729--736},
	year={2006}
}
@article{goodfellow2014generative,
	title={Generative adversarial nets},
	author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	journal=NeurIPS,
	volume={27},
	year={2014}
}
@article{finn2016connection,
	title={A connection between generative adversarial networks, inverse reinforcement learning, and energy-based models},
	author={Finn, Chelsea and Christiano, Paul and Abbeel, Pieter and Levine, Sergey},
	journal={arXiv preprint arXiv:1611.03852},
	year={2016}
}
@article{tzeng2014deep,
	title={Deep domain confusion: Maximizing for domain invariance},
	author={Tzeng, Eric and Hoffman, Judy and Zhang, Ning and Saenko, Kate and Darrell, Trevor},
	journal={arXiv preprint arXiv:1412.3474},
	year={2014}
}
@article{ganin2016domain,
	title={Domain-adversarial training of neural networks},
	author={Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran{\c{c}}ois and Marchand, Mario and Lempitsky, Victor},
	journal=jmlr,
	volume={17},
	number={1},
	pages={2096--2030},
	year={2016},
	publisher={JMLR. org}
}
@incollection{tzeng2020adapting,
	title={Adapting deep visuomotor representations with weak pairwise constraints},
	author={Tzeng, Eric and Devin, Coline and Hoffman, Judy and Finn, Chelsea and Abbeel, Pieter and Levine, Sergey and Saenko, Kate and Darrell, Trevor},
	booktitle={Algorithmic Foundations of Robotics XII},
	pages={688--703},
	year={2020},
	publisher={Springer}
}
@article{eysenbach2020off,
	title={Off-dynamics reinforcement learning: Training for transfer with domain classifiers},
	author={Eysenbach, Benjamin and Asawa, Swapnil and Chaudhari, Shreyas and Levine, Sergey and Salakhutdinov, Ruslan},
	journal={arXiv preprint arXiv:2006.13916},
	year={2020}
}
@inproceedings{andreas2017modular,
	title={Modular multitask reinforcement learning with policy sketches},
	author={Andreas, Jacob and Klein, Dan and Levine, Sergey},
	booktitle=icml,
	pages={166--175},
	year={2017},
	organization={PMLR}
}
@article{florensa2017stochastic,
	title={Stochastic neural networks for hierarchical reinforcement learning},
	author={Florensa, Carlos and Duan, Yan and Abbeel, Pieter},
	journal={arXiv preprint arXiv:1704.03012},
	year={2017}
}
@article{kumar2020one,
	title={One solution is not all you need: Few-shot extrapolation via structured maxent rl},
	author={Kumar, Saurabh and Kumar, Aviral and Levine, Sergey and Finn, Chelsea},
	journal=NeurIPS,
	volume={33},
	pages={8198--8210},
	year={2020}
}
@article{rajeswaran2016epopt,
	title={Epopt: Learning robust neural network policies using model ensembles},
	author={Rajeswaran, Aravind and Ghotra, Sarvjeet and Ravindran, Balaraman and Levine, Sergey},
	journal={arXiv preprint arXiv:1610.01283},
	year={2016}
}
@article{yu2017preparing,
	title={Preparing for the unknown: Learning a universal policy with online system identification},
	author={Yu, Wenhao and Tan, Jie and Liu, C Karen and Turk, Greg},
	journal={arXiv preprint arXiv:1702.02453},
	year={2017}
}
@article{sadeghi2016cad2rl,
	title={Cad2rl: Real single-image flight without a single real image},
	author={Sadeghi, Fereshteh and Levine, Sergey},
	journal={arXiv preprint arXiv:1611.04201},
	year={2016}
}
@inproceedings{tobin2017domain,
	title={Domain randomization for transferring deep neural networks from simulation to the real world},
	author={Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
	booktitle=iros,
	pages={23--30},
	year={2017},
	organization={IEEE}
}
@inproceedings{james2017transferring,
	title={Transferring end-to-end visuomotor control from simulation to real world for a multi-stage task},
	author={James, Stephen and Davison, Andrew J and Johns, Edward},
	booktitle={Conference on Robot Learning},
	pages={334--343},
	year={2017},
	organization={PMLR}
}
@inproceedings{bousmalis2018using,
	title={Using simulation and domain adaptation to improve efficiency of deep robotic grasping},
	author={Bousmalis, Konstantinos and Irpan, Alex and Wohlhart, Paul and Bai, Yunfei and Kelcey, Matthew and Kalakrishnan, Mrinal and Downs, Laura and Ibarz, Julian and Pastor, Peter and Konolige, Kurt and others},
	booktitle=icra,
	pages={4243--4250},
	year={2018},
	organization={IEEE}
}
@inproceedings{rao2020rl,
	title={Rl-cyclegan: Reinforcement learning aware simulation-to-real},
	author={Rao, Kanishka and Harris, Chris and Irpan, Alex and Levine, Sergey and Ibarz, Julian and Khansari, Mohi},
	booktitle=cvpr,
	pages={11157--11166},
	year={2020}
}
@article{dayan1993improving,
	title={Improving generalization for temporal difference learning: The successor representation},
	author={Dayan, Peter},
	journal={Neural Computation},
	volume={5},
	number={4},
	pages={613--624},
	year={1993},
	publisher={MIT Press}
}
@inproceedings{finn2017model,
	title={Model-agnostic meta-learning for fast adaptation of deep networks},
	author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
	booktitle=icml,
	pages={1126--1135},
	year={2017},
	organization={PMLR}
}
@inproceedings{foerster2018dice,
	title={Dice: The infinitely differentiable monte carlo estimator},
	author={Foerster, Jakob and Farquhar, Gregory and Al-Shedivat, Maruan and Rockt{\"a}schel, Tim and Xing, Eric and Whiteson, Shimon},
	booktitle=icml,
	pages={1529--1538},
	year={2018},
	organization={PMLR}
}
@article{rothfuss2018promp,
	title={Promp: Proximal meta-policy search},
	author={Rothfuss, Jonas and Lee, Dennis and Clavera, Ignasi and Asfour, Tamim and Abbeel, Pieter},
	journal={arXiv preprint arXiv:1810.06784},
	year={2018}
}
@article{gupta2018meta,
	title={Meta-reinforcement learning of structured exploration strategies},
	author={Gupta, Abhishek and Mendonca, Russell and Liu, YuXuan and Abbeel, Pieter and Levine, Sergey},
	journal=NeurIPS,
	volume={31},
	year={2018}
}
@article{stadie2018some,
	title={Some considerations on learning to explore via meta-reinforcement learning},
	author={Stadie, Bradly C and Yang, Ge and Houthooft, Rein and Chen, Xi and Duan, Yan and Wu, Yuhuai and Abbeel, Pieter and Sutskever, Ilya},
	journal={arXiv preprint arXiv:1803.01118},
	year={2018}
}
@article{houthooft2018evolved,
	title={Evolved policy gradients},
	author={Houthooft, Rein and Chen, Yuhua and Isola, Phillip and Stadie, Bradly and Wolski, Filip and Jonathan Ho, OpenAI and Abbeel, Pieter},
	journal=NeurIPS,
	volume={31},
	year={2018}
}
@inproceedings{fernando2018meta,
	title={Meta-learning by the baldwin effect},
	author={Fernando, Chrisantha and Sygnowski, Jakub and Osindero, Simon and Wang, Jane and Schaul, Tom and Teplyashin, Denis and Sprechmann, Pablo and Pritzel, Alexander and Rusu, Andrei},
	booktitle={Proceedings of the Genetic and Evolutionary Computation Conference Companion},
	pages={1313--1320},
	year={2018}
}
@inproceedings{rakelly2019efficient,
	title={Efficient off-policy meta-reinforcement learning via probabilistic context variables},
	author={Rakelly, Kate and Zhou, Aurick and Finn, Chelsea and Levine, Sergey and Quillen, Deirdre},
	booktitle=icml,
	pages={5331--5340},
	year={2019},
	organization={PMLR}
}
@inproceedings{zintgraf2019variational,
	title={Variational task embeddings for fast adapta-tion in deep reinforcement learning},
	author={Zintgraf, Luisa and Igl, Maximilian and Shiarlis, Kyriacos and Mahajan, Anuj and Hofmann, Katja and Whiteson, Shimon},
	booktitle={International Conference on Learning Representations Workshop (ICLRW)},
	year={2019}
}
@article{humplik2019meta,
	title={Meta reinforcement learning as task inference},
	author={Humplik, Jan and Galashov, Alexandre and Hasenclever, Leonard and Ortega, Pedro A and Teh, Yee Whye and Heess, Nicolas},
	journal={arXiv preprint arXiv:1905.06424},
	year={2019}
}
@inproceedings{ritter2018been,
	title={Been there, done that: Meta-learning with episodic recall},
	author={Ritter, Samuel and Wang, Jane and Kurth-Nelson, Zeb and Jayakumar, Siddhant and Blundell, Charles and Pascanu, Razvan and Botvinick, Matthew},
	booktitle=icml,
	pages={4354--4363},
	year={2018},
	organization={PMLR}
}
@article{wang2018prefrontal,
	title={Prefrontal cortex as a meta-reinforcement learning system},
	author={Wang, Jane X and Kurth-Nelson, Zeb and Kumaran, Dharshan and Tirumala, Dhruva and Soyer, Hubert and Leibo, Joel Z and Hassabis, Demis and Botvinick, Matthew},
	journal={Nature neuroscience},
	volume={21},
	number={6},
	pages={860--868},
	year={2018},
	publisher={Nature Publishing Group}
}
@article{dasgupta2019causal,
	title={Causal reasoning from meta-reinforcement learning},
	author={Dasgupta, Ishita and Wang, Jane and Chiappa, Silvia and Mitrovic, Jovana and Ortega, Pedro and Raposo, David and Hughes, Edward and Battaglia, Peter and Botvinick, Matthew and Kurth-Nelson, Zeb},
	journal={arXiv preprint arXiv:1901.08162},
	year={2019}
}
@inproceedings{fujimoto2018addressing,
	title={Addressing function approximation error in actor-critic methods},
	author={Fujimoto, Scott and Hoof, Herke and Meger, David},
	booktitle=icml,
	pages={1587--1596},
	year={2018},
	organization={PMLR}
}
@article{wang2016learning,
	title={Learning to reinforcement learn},
	author={Wang, Jane X and Kurth-Nelson, Zeb and Tirumala, Dhruva and Soyer, Hubert and Leibo, Joel Z and Munos, Remi and Blundell, Charles and Kumaran, Dharshan and Botvinick, Matt},
	journal={arXiv preprint arXiv:1611.05763},
	year={2016}
}
@article{duan2016rl,
	title={RL2: Fast reinforcement learning via slow reinforcement learning},
	author={Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L and Sutskever, Ilya and Abbeel, Pieter},
	journal={arXiv preprint arXiv:1611.02779},
	year={2016}
}
@article{liu2020explore,
	title={Explore then Execute: Adapting without Rewards via Factorized Meta-Reinforcement Learning},
	author={Liu, Evan Zheran and Raghunathan, Aditi and Liang, Percy and Finn, Chelsea},
	year={2020}
}
@book{sutton2018reinforcement,
	title={Reinforcement learning: An introduction},
	author={Sutton, Richard S and Barto, Andrew G},
	year={2018},
	publisher={MIT press}
}
@article{caldera2018review,
	title={Review of deep learning methods in robotic grasp detection},
	author={Caldera, Shehan and Rassau, Alexander and Chai, Douglas},
	journal={Multimodal Technologies and Interaction},
	volume={2},
	number={3},
	pages={57},
	year={2018},
	publisher={MDPI}
}
@article{calandra2017feeling,
	title={The feeling of success: Does touch sensing help predict grasp outcomes?},
	author={Calandra, Roberto and Owens, Andrew and Upadhyaya, Manu and Yuan, Wenzhen and Lin, Justin and Adelson, Edward H and Levine, Sergey},
	journal={arXiv preprint arXiv:1710.05512},
	year={2017}
}
@article{haddadin2018tactile,
	title={Tactile robots as a central embodiment of the tactile Internet},
	author={Haddadin, Sami and Johannsmeier, Lars and Ledezma, Fernando D{\'\i}az},
	journal={Proceedings of the IEEE},
	volume={107},
	number={2},
	pages={471--487},
	year={2018},
	publisher={IEEE}
}
@misc{moley,
	title = {Moley Robotics},
	howpublished = {\url{https://moley.com/}},
	note = {Accessed: 2022/06/16}
}
@misc{bothandy,
	title = {Bot Handy Samsung},
	howpublished = {\url{https://research.samsung.com/robot}},
	note = {Accessed: 2022/06/16}
}
@misc{coffeemaster,
	title = {Coffee Master OrionStar},
	howpublished = {\url{https://en.orionstar.com/coffeemaster.html}},
	note = {Accessed: 2022/06/16}
}
@inproceedings{li2019review,
	title={A review: Machine learning on robotic grasping},
	author={Li, Youhao and Lei, Qujiang and Cheng, ChaoPeng and Zhang, Gong and Wang, Weijun and Xu, Zheng},
	booktitle={Eleventh International Conference on Machine Vision (ICMV 2018)},
	volume={11041},
	pages={775--783},
	year={2019},
	organization={SPIE}
}
@article{bekiroglu2011assessing,
	title={Assessing grasp stability based on learning and haptic data},
	author={Bekiroglu, Yasemin and Laaksonen, Janne and Jorgensen, Jimmy Alison and Kyrki, Ville and Kragic, Danica},
	journal={IEEE Transactions on Robotics},
	volume={27},
	number={3},
	pages={616--629},
	year={2011},
	publisher={IEEE}
}
@inproceedings{li2014learning,
	title={Learning of grasp adaptation through experience and tactile sensing},
	author={Li, Miao and Bekiroglu, Yasemin and Kragic, Danica and Billard, Aude},
	booktitle=iros,
	pages={3339--3346},
	year={2014},
	organization={IEEE}
}
@inproceedings{handa2020dexpilot,
	title={Dexpilot: Vision-based teleoperation of dexterous robotic hand-arm system},
	author={Handa, Ankur and Van Wyk, Karl and Yang, Wei and Liang, Jacky and Chao, Yu-Wei and Wan, Qian and Birchfield, Stan and Ratliff, Nathan and Fox, Dieter},
	booktitle=icra,
	pages={9164--9170},
	year={2020},
	organization={IEEE}
}
@inproceedings{finn2017one,
	title={One-shot visual imitation learning via meta-learning},
	author={Finn, Chelsea and Yu, Tianhe and Zhang, Tianhao and Abbeel, Pieter and Levine, Sergey},
	booktitle={Conference on Robot Learning},
	pages={357--368},
	year={2017},
	organization={PMLR}
}
@article{sharma2019third,
	title={Third-person visual imitation learning via decoupled hierarchical controller},
	author={Sharma, Pratyusha and Pathak, Deepak and Gupta, Abhinav},
	journal=NeurIPS,
	volume={32},
	year={2019}
}
@article{kleeberger2020survey,
	title={A survey on learning-based robotic grasping},
	author={Kleeberger, Kilian and Bormann, Richard and Kraus, Werner and Huber, Marco F},
	journal={Current Robotics Reports},
	volume={1},
	number={4},
	pages={239--249},
	year={2020},
	publisher={Springer}
}
@article{bohg2013data,
	title={Data-driven grasp synthesis—a survey},
	author={Bohg, Jeannette and Morales, Antonio and Asfour, Tamim and Kragic, Danica},
	journal={IEEE Transactions on robotics},
	volume={30},
	number={2},
	pages={289--309},
	year={2013},
	publisher={IEEE}
}
@Comment{jabref-meta: databaseType:bibtex;}